package deepseek

import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"

	deepseek "github.com/p9966/go-deepseek/internal"
)

type StreamChatCompletionRequest struct {
	Stream           bool                    `json:"stream"`
	Model            string                  `json:"model"`
	Messages         []ChatCompletionMessage `json:"messages"`
	FrequencyPenalty float32                 `json:"frequency_penalty"`
	MaxTokens        int                     `json:"max_tokens,omitempty"`       // Optional: Maximum tokens, > 1
	PresencePenalty  float32                 `json:"presence_penalty,omitempty"` // Optional: Presence penalty, >= -2 and <= 2
	Temperature      float32                 `json:"temperature,omitempty"`      // Optional: Sampling temperature, <= 2
	TopP             float32                 `json:"top_p,omitempty"`            // Optional: Nucleus sampling parameter, <= 1
	ResponseFormat   *ResponseFormat         `json:"response_format,omitempty"`  // Optional: Custom response format
	Stop             []string                `json:"stop,omitempty"`             // Optional: Stop signals
	Tools            []Tools                 `json:"tools,omitempty"`            // Optional: List of tools
	LogProbs         bool                    `json:"logprobs,omitempty"`         // Optional: Enable log probabilities
	TopLogProbs      int                     `json:"top_logprobs,omitempty"`     // Optional: Number of top tokens with log probabilities, <= 20
}

type StreamChatCompletionResponse struct {
	ID                string              `json:"id"`                 // Unique identifier for the chat completion.
	Object            string              `json:"object"`             // Type of the object, typically "chat.completion".
	Created           int64               `json:"created"`            // Timestamp when the chat completion was created.
	Model             string              `json:"model"`              // The model used for generating the completion.
	Choices           []StreamChatChoices `json:"choices"`            // List of completion choices generated by the model.
	SystemFingerprint string              `json:"system_fingerprint"` // Fingerprint of the system configuration.
}

type StreamChatChoices struct {
	Index        int                  `json:"index"`              // Index of the choice in the list of choices.
	Delta        StreamChatChoiceData `json:"delta"`              // The message generated by the model.
	LogProbs     *LogProbs            `json:"logprobs,omitempty"` // Log probabilities of the tokens, if available.
	FinishReason string               `json:"finish_reason"`      // Reason why the completion finished.
}

type StreamChatChoiceData struct {
	Content string `json:"content"`
}

type ChatCompletionStream interface {
	Recv() (*StreamChatCompletionResponse, error)
	Close() error
}

type chatCompletionStream struct {
	ctx    context.Context
	cancel context.CancelFunc
	resp   *http.Response
	reader *bufio.Reader
}

func (s *chatCompletionStream) Recv() (*StreamChatCompletionResponse, error) {
	reader := s.reader
	for {
		line, err := reader.ReadString('\n')
		if err != nil {
			return nil, err
		}

		line = strings.TrimSpace(line)
		if line == "data: [DONE]" {
			return nil, io.EOF
		}
		if len(line) < 7 || line[:6] != "data: " {
			continue
		}

		var resp StreamChatCompletionResponse
		if err := json.Unmarshal([]byte(line[6:]), &resp); err != nil {
			return nil, err
		}

		return &resp, nil
	}
}

func (s *chatCompletionStream) Close() error {
	s.cancel()
	return s.resp.Body.Close()
}

func (c *Client) CreateChatCompletionStream(ctx context.Context, req StreamChatCompletionRequest) (ChatCompletionStream, error) {
	req.Stream = true
	request, err := deepseek.NewRequestBuilder(c.AuthToken).SetBaseUrl(c.BaseUrl).SetPath(chatCompletionSuffix).SetBody(req).Build(ctx)
	if err != nil {
		return nil, err
	}

	resp, err := c.Do(request)
	if err != nil {
		return nil, err
	}

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("unexpected status code: %d", resp.StatusCode)
	}

	ctx, cancel := context.WithCancel(ctx)
	stream := &chatCompletionStream{
		ctx:    ctx,
		cancel: cancel,
		resp:   resp,
		reader: bufio.NewReader(resp.Body),
	}
	return stream, nil
}
